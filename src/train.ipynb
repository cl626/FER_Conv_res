{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import model\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "shape = (44, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, transform=None, images=None, emotions=None):\n",
    "        self.transform = transform\n",
    "        self.images = images\n",
    "        self.emotions = emotions\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        emotion = self.emotions[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, emotion\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAwADABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APP9Ihu9XmRI1XHdnOcfhXpui+HbHT7faEEsjD55GHJ/wFbKaJp0jbmtIiR3Kita3sbWJNscKAD0Fcb4/s0tktrmLCCYtCx7bsZU/oRXlM5feQeVxzx3ruvC2jjTtOWQnLuNx9q3U1+zsyVlMhPcKM1atvFmjySeUL/y29HXpW3BrVrJg7gV4AcHgmuY+JV2kvh+18t1YC7Qkq2cABq8ulAKsPavT/DxE1lCJQVJQZB7VNqvhG2vlJEaliCNxYjg+noayF8BWsccZClDGMZ3ZLnOcmtDWvCtzc+HrWPTrxrcpIfM2jO4Y4/rXKeJ9MGjwQWiySMsiGYCTqOQP6Guff7uc84rvNOlaB0GcL0rrLS6yAGJx6dqqavq1tayJ50628OCS7cD6VoaTrWlXtosNteRzOxyFVs5HeuA+IVyl1rCxpj9xAFOPUkn/CuRQhoB9MV1NlfI+zn9etdNZ3eYmJ6rWbqev6Y4FvePEu1ujRkkfpVzRr3SrKwu7m0aFo4wZHaMY6dufXNcium6nrb3OotCwgO55J3BCD2B7/QVV1DRJtJkCfabS7jPSW1lDDPoe4NZ3mXWnuS0bPCDkOoyB/hXT6JrC3DjbIPXGa6WVdYcE2v2RlIBBl5/Ss++un1nVbTw3NLbwPIpkunVsfKOQq+5Paptb0q5ub600qxUPZRx7AzNtCsD+vGK5a50ufSbqXdCsqxkiWAjcG9xX//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=48x48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size 28709 : private val size 3589 : public val size 3589\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "class DataSetFactory():\n",
    "\n",
    "    def __init__(self):\n",
    "        images = []\n",
    "        emotions = []\n",
    "        private_images = []\n",
    "        private_emotions = []\n",
    "        public_images = []\n",
    "        public_emotions = []\n",
    "\n",
    "        cnt=0\n",
    "        with open('../dataset/fer2013.csv', 'r') as csvin:\n",
    "            data = csv.reader(csvin)\n",
    "            next(data)\n",
    "            for row in data:\n",
    "                face = [int(pixel) for pixel in row[1].split()]\n",
    "                face = np.asarray(face).reshape(48, 48)\n",
    "                face = face.astype('uint8')\n",
    "                if(cnt==0):\n",
    "                    img=Image.fromarray(face)\n",
    "                    display(img)\n",
    "                    cnt+=1\n",
    "\n",
    "                if row[-1] == 'Training':\n",
    "                    emotions.append(int(row[0]))\n",
    "                    images.append(Image.fromarray(face))\n",
    "                elif row[-1] == \"PrivateTest\":\n",
    "                    private_emotions.append(int(row[0]))\n",
    "                    private_images.append(Image.fromarray(face))\n",
    "                elif row[-1] == \"PublicTest\":\n",
    "                    public_emotions.append(int(row[0]))\n",
    "                    public_images.append(Image.fromarray(face))\n",
    "\n",
    "        print('training size %d : private val size %d : public val size %d' % (\n",
    "            len(images), len(private_images), len(public_images)))\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(shape[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.CenterCrop(shape[0]),\n",
    "            ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.training = DataSet(transform=train_transform, images=images, emotions=emotions)\n",
    "        self.private = DataSet(transform=val_transform, images=private_images, emotions=private_emotions)\n",
    "        self.public = DataSet(transform=val_transform, images=public_images, emotions=public_emotions)\n",
    "\n",
    "datas=DataSetFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # variables  -------------\n",
    "    batch_size = 128\n",
    "    lr = 0.01\n",
    "    epochs = 300\n",
    "    learning_rate_decay_start = 80\n",
    "    learning_rate_decay_every = 5\n",
    "    learning_rate_decay_rate = 0.9\n",
    "    # ------------------------\n",
    "\n",
    "    classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    network = model.Model(num_classes=len(classes)).to(device)\n",
    "    if not torch.cuda.is_available():\n",
    "        summary(network, (1, shape[0], shape[1]))\n",
    "\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr, momentum=0.9, weight_decay=5e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    factory = DataSetFactory()\n",
    "\n",
    "    training_loader = DataLoader(factory.training, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    validation_loader = {\n",
    "        'private': DataLoader(factory.private, batch_size=batch_size, shuffle=True, num_workers=1),\n",
    "        'public': DataLoader(factory.public, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    }\n",
    "\n",
    "    min_validation_loss = {\n",
    "        'private': 10000,\n",
    "        'public': 10000,\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        network.train()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        total_train_loss = 0\n",
    "        if epoch > learning_rate_decay_start and learning_rate_decay_start >= 0:\n",
    "\n",
    "            #\n",
    "            frac = (epoch - learning_rate_decay_start) // learning_rate_decay_every\n",
    "            decay_factor = learning_rate_decay_rate ** frac\n",
    "            current_lr = lr * decay_factor\n",
    "            for group in optimizer.param_groups:\n",
    "                group['lr'] = current_lr\n",
    "        else:\n",
    "            current_lr = lr\n",
    "\n",
    "        print('learning_rate: %s' % str(current_lr))\n",
    "        for i, (x_train, y_train) in enumerate(training_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x_train = x_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            y_predicted = network(x_train)\n",
    "            loss = criterion(y_predicted, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(y_predicted.data, 1)\n",
    "            total_train_loss += loss.data\n",
    "            total += y_train.size(0)\n",
    "            correct += predicted.eq(y_train.data).sum()\n",
    "        accuracy = 100. * float(correct) / total\n",
    "        print('Epoch [%d/%d] Training Loss: %.4f, Accuracy: %.4f' % (\n",
    "            epoch + 1, epochs, total_train_loss / (i + 1), accuracy))\n",
    "\n",
    "        network.eval()\n",
    "        with torch.no_grad():\n",
    "            for name in ['private', 'public']:\n",
    "                total = 0\n",
    "                correct = 0\n",
    "                total_validation_loss = 0\n",
    "                for j, (x_val, y_val) in enumerate(validation_loader[name]):\n",
    "                    x_val = x_val.to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    y_val_predicted = network(x_val)\n",
    "                    val_loss = criterion(y_val_predicted, y_val)\n",
    "                    _, predicted = torch.max(y_val_predicted.data, 1)\n",
    "                    total_validation_loss += val_loss.data\n",
    "                    total += y_val.size(0)\n",
    "                    correct += predicted.eq(y_val.data).sum()\n",
    "\n",
    "                accuracy = 100. * float(correct) / total\n",
    "                if total_validation_loss <= min_validation_loss[name]:\n",
    "                    if epoch >= 10:\n",
    "                        print('saving new model')\n",
    "                        state = {'net': network.state_dict()}\n",
    "                        torch.save(state, '../trained/%s_model_%d_%d.t7' % (name, epoch + 1, accuracy))\n",
    "                    min_validation_loss[name] = total_validation_loss\n",
    "\n",
    "                print('Epoch [%d/%d] %s validation Loss: %.4f, Accuracy: %.4f' % (\n",
    "                    epoch + 1, epochs, name, total_validation_loss / (j + 1), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
